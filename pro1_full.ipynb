{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d06f5576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "data = pd.read_csv('New_Wireless_Pipe.txt', sep=\"|\")\n",
    "cnn = sqlite3.connect('juypter_sql_tutorial.db')\n",
    "# data.to_sql('df', cnn)\n",
    "%load_ext sql\n",
    "%sql sqlite:///juypter_sql_tutorial.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3ecdeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1: check if the data has duplicate records\n",
    "# spark.sql(\"\"\"\n",
    "# ​\n",
    "# \"\"\").show()\n",
    "# +------+\n",
    "# |is_dup|\n",
    "# +------+\n",
    "# | false|\n",
    "# +------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc484b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///juypter_sql_tutorial.db\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>is_dup</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>false</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[('false',)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "\n",
    "SELECT (case when max(count) =1 then 'false' ELSE 'true' end ) AS is_dup\n",
    "FROM(\n",
    "SELECT acctno, count(acctno) AS count\n",
    "FROM df\n",
    "GROUP BY acctno) AS t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47ff553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2: plase list 2nd place sales account no. for each dealertype; then how to display top3 ?\n",
    "# spark.sql(\"\"\"\n",
    "# ​\n",
    "# ​\n",
    "# \"\"\").show()\n",
    "# +----------+-------------+-----+----+\n",
    "# |dealertype|       acctno|sales|rank|\n",
    "# +----------+-------------+-----+----+\n",
    "# |        A2|1879712055400| 1200|   2|\n",
    "# |        B1|2111710057053| 1200|   2|\n",
    "# |        C1|2344491947376| 1199|   2|\n",
    "# |        A1|1595694049314| 1200|   2|\n",
    "# +----------+-------------+-----+----+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04a9596",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM(\n",
    "SELECT dealertype, acctno, sales, row_number() OVER(PARTITION BY dealertype ORDER BY sales DESC) AS rank\n",
    "FROM df\n",
    "ORDER BY sales DESC)\n",
    "WHERE rank = 2\n",
    "\n",
    "# rank = 相同的同一排名\n",
    "# row_num = 相同值 按順序排a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4b7c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# +----------+-------------+-----+----+\n",
    "# |dealertype|       acctno|sales|rank|\n",
    "# +----------+-------------+-----+----+\n",
    "# |        A2|1329951214050| 1200|   1|\n",
    "# |        A2|1879712055400| 1200|   2|\n",
    "# |        A2|1415944669550| 1199|   3|\n",
    "# |        B1|1538431934945| 1200|   1|\n",
    "# |        B1|2111710057053| 1200|   2|\n",
    "# |        B1|2220633276528| 1199|   3|\n",
    "# |        C1|1556976795264| 1199|   1|\n",
    "# |        C1|2344491947376| 1199|   2|\n",
    "# |        C1|2389693376124| 1199|   3|\n",
    "# |        A1|1538055998888| 1200|   1|\n",
    "# |        A1|1595694049314| 1200|   2|\n",
    "# |        A1|1897085618697| 1200|   3|\n",
    "# +----------+-------------+-----+----+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb14fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM(\n",
    "SELECT dealertype, acctno, sales, row_number() OVER(PARTITION BY dealertype ORDER BY sales DESC) AS rank\n",
    "FROM df\n",
    "ORDER BY sales DESC)\n",
    "WHERE rank <= 3\n",
    "ORDER BY dealertype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229be353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3, display a list of rateplan, where the most popular rate plan on the top, and display how many users choose each plan, and what is the total sales for each plan\n",
    "# spark.sql(\"\"\"\n",
    "# ​\n",
    "# \"\"\").show()\n",
    "# +--------+---------+-----------+\n",
    "# |rateplan|use_count|total_sales|\n",
    "# +--------+---------+-----------+\n",
    "# |       1|    68194|   11306589|\n",
    "# |       2|    20187|    3384503|\n",
    "# |       3|    13874|    2282611|\n",
    "# +--------+---------+-----------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164f4c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "\n",
    "SELECT rateplan, count(rateplan) AS use_count, sum(sales) AS total_sales\n",
    "FROM df\n",
    "GROUP BY rateplan\n",
    "ORDER BY count(rateplan) DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9f899e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4 get the dealertype for rateplan's user more than 10,000, sort descending order by user_count\n",
    "# spark.sql(\"\"\"\n",
    "# ​\n",
    "# \"\"\").show()\n",
    "# +----------+--------+----------+\n",
    "# |dealertype|rateplan|user_count|\n",
    "# +----------+--------+----------+\n",
    "# |        A1|       1|     35875|\n",
    "# |        B1|       1|     14239|\n",
    "# |        A1|       2|     11837|\n",
    "# |        C1|       1|     10105|\n",
    "# +----------+--------+----------+\n",
    "\n",
    "# Let's duplicate the data and do some dedup exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1066275",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT dealertype, rateplan, count(rateplan) AS user_count\n",
    "FROM df\n",
    "GROUP BY dealertype, rateplan\n",
    "HAVING count(rateplan) >10000\n",
    "ORDER BY count(rateplan) DESC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d208cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5, get the number of rows,the num of acct and the num of unique accounts using table new_data\n",
    "# #use sql to display\n",
    "# df_stat = spark.sql(\"\"\"\n",
    "# ​\n",
    "# \"\"\")\n",
    "# df_stat.show()\n",
    "# +------+------+----------+\n",
    "# |   Obs| Accts|Uniq_Accts|\n",
    "# +------+------+----------+\n",
    "# |102265|102265|    102255|\n",
    "# +------+------+----------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a4d53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT COUNT(*) AS Obs, COUNT(acctno) AS Accts, COUNT(DISTINCT acctno) AS Uniq_Accts\n",
    "FROM df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f48240b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6 HOW TO CREATE A DATASET WITHOUT DUPLICATE RECORD?\n",
    "# think about how to do that via pandas and sql\n",
    "\n",
    "# df_uniq = spark.sql(\"\"\"\n",
    "# ​\n",
    "# \"\"\")\n",
    "# print('the record count for the dataframe is :',df_uniq.count())\n",
    "# the record count for the dataframe is : 102255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdad8e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = \"\"\"\n",
    "    SELECT COUNT(DISTINCT acctno) AS count\n",
    "    FROM df\n",
    "    PRINT\n",
    "\"\"\"\n",
    "\n",
    "df_uniq = pd.read_sql_query(df, cnn)\n",
    "print('the record count for the dataframe is :',df_uniq['count'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6c36c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7 HOW TO CREATE A DATASET WITH ALL THE DUPLICATED RECORD?\n",
    "# ​\n",
    "# df_dup = spark.sql(\"\"\"\n",
    "# ​\n",
    "# \"\"\")\n",
    "# df_dup.show()\n",
    "# +-------------+----------+----------+-----------+----------+--------+----------+---+--------+-----+------+\n",
    "# |       acctno|     actdt|   deactdt|deactreason|goodcredit|rateplan|dealertype|AGE|Province|sales|dup_ct|\n",
    "# +-------------+----------+----------+-----------+----------+--------+----------+---+--------+-----+------+\n",
    "# |1176913194483|06/20/1999|      null|       null|         0|       1|        A1| 58|      BC|  128|     2|\n",
    "# |1176913194483|06/20/1999|      null|       null|         0|       1|        A1| 58|      BC|  128|     2|\n",
    "# |1176951913656|07/01/2000|      null|       null|         0|       1|        A1| 57|      BC|  593|     2|\n",
    "# |1176951913656|07/01/2000|      null|       null|         0|       1|        A1| 57|      BC|  593|     2|\n",
    "# |1176991056273|08/31/1999|09/18/2000|       MOVE|         1|       1|        C1| 92|      QC| 1041|     2|\n",
    "# |1176991056273|08/31/1999|09/18/2000|       MOVE|         1|       1|        C1| 92|      QC| 1041|     2|\n",
    "# |1176991866552|05/24/2000|      null|       null|         1|       1|        A1| 77|      ON| null|     2|\n",
    "# |1176991866552|05/24/2000|      null|       null|         1|       1|        A1| 77|      ON| null|     2|\n",
    "# |1176992889500|11/28/2000|      null|       null|         1|       1|        C1| 68|      AB|   72|     2|\n",
    "# |1176992889500|11/28/2000|      null|       null|         1|       1|        C1| 68|      AB|   72|     2|\n",
    "# |1177010940613|12/09/1999|      null|       null|         1|       2|        A1| 42|      NS|   11|     2|\n",
    "# |1177010940613|12/09/1999|      null|       null|         1|       2|        A1| 42|      NS|   11|     2|\n",
    "# |1176954000288|05/30/2000|      null|       null|         1|       2|        A1| 47|      ON|   83|     2|\n",
    "# |1176954000288|05/30/2000|      null|       null|         1|       2|        A1| 47|      ON|   83|     2|\n",
    "# |1176914599423|10/04/1999|10/15/1999|       NEED|         1|       1|        A1| 45|      AB|   72|     2|\n",
    "# |1176914599423|10/04/1999|10/15/1999|       NEED|         1|       1|        A1| 45|      AB|   72|     2|\n",
    "# |1176969186303|12/13/2000|      null|       null|         1|       1|        C1| 82|      BC| null|     2|\n",
    "# |1176969186303|12/13/2000|      null|       null|         1|       1|        C1| 82|      BC| null|     2|\n",
    "# |1177000067271|12/23/1999|      null|       null|         0|       1|        B1| 75|      ON|  134|     2|\n",
    "# |1177000067271|12/23/1999|      null|       null|         0|       1|        B1| 75|      ON|  134|     2|\n",
    "# +-------------+----------+----------+-----------+----------+--------+----------+---+--------+-----+------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ac10fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "\n",
    "SELECT t.acctno, t.actdt, t.deactdt, t.deactreason, t.goodcredit, t.rateplan, t.dealertype, t.AGE, t.Province, t.sales, t.count\n",
    "FROM df1 AS s\n",
    "INNER JOIN (\n",
    "SELECT *, count(*) AS count\n",
    "FROM df1\n",
    "GROUP BY acctno\n",
    "HAVING COUNT(*) >1) AS t\n",
    "ON s.acctno = t.acctno"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
